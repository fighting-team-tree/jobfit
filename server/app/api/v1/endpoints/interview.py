"""
Interview API Endpoints

Handles real-time mock interview via WebSocket with ElevenLabs TTS.
"""
import asyncio
import json
import base64
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, HTTPException
from pydantic import BaseModel
from typing import Optional, List
from datetime import datetime

from app.services.nvidia_service import nvidia_service
from app.services.elevenlabs_service import elevenlabs_service

router = APIRouter()


# ============ Request/Response Models ============

class InterviewSession(BaseModel):
    """Interview session state."""
    session_id: str
    profile: dict
    jd_text: str
    persona: str = "professional"  # professional, friendly, challenging
    conversation_history: List[dict] = []
    question_count: int = 0
    max_questions: int = 5
    started_at: Optional[str] = None
    ended_at: Optional[str] = None


class StartInterviewRequest(BaseModel):
    """Request to start a new interview session."""
    profile: dict
    jd_text: str
    persona: str = "professional"
    max_questions: int = 5


class InterviewFeedbackResponse(BaseModel):
    """Interview feedback after session ends."""
    session_id: str
    total_questions: int
    duration_seconds: int
    conversation: List[dict]
    feedback_summary: str
    scores: dict


# ============ In-memory session storage ============
# In production, use Redis or database
active_sessions: dict[str, InterviewSession] = {}


# ============ REST Endpoints ============

@router.get("/")
def read_root():
    """Health check for interview module."""
    return {"module": "interview", "status": "healthy"}


@router.post("/start")
async def start_interview(request: StartInterviewRequest):
    """
    Initialize a new interview session.
    
    Returns session_id and first question.
    """
    import uuid
    session_id = str(uuid.uuid4())[:8]
    
    session = InterviewSession(
        session_id=session_id,
        profile=request.profile,
        jd_text=request.jd_text,
        persona=request.persona,
        max_questions=request.max_questions,
        started_at=datetime.now().isoformat()
    )
    
    # Generate first question
    try:
        first_question = await nvidia_service.generate_interview_question(
            profile=request.profile,
            jd_text=request.jd_text,
            conversation_history=[],
            persona=request.persona
        )
        
        session.conversation_history.append({
            "role": "interviewer",
            "content": first_question,
            "timestamp": datetime.now().isoformat()
        })
        session.question_count = 1
        
        active_sessions[session_id] = session
        
        return {
            "session_id": session_id,
            "question": first_question,
            "question_number": 1,
            "total_questions": request.max_questions,
            "persona": request.persona
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start interview: {str(e)}")


@router.post("/{session_id}/respond")
async def respond_to_question(session_id: str, answer: str):
    """
    Submit an answer and get the next question.
    
    - **session_id**: Active session ID
    - **answer**: User's answer to the current question
    """
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session = active_sessions[session_id]
    
    # Record user's answer
    session.conversation_history.append({
        "role": "candidate",
        "content": answer,
        "timestamp": datetime.now().isoformat()
    })
    
    # Check if we've reached max questions
    if session.question_count >= session.max_questions:
        session.ended_at = datetime.now().isoformat()
        return {
            "session_id": session_id,
            "status": "completed",
            "message": "ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í”¼ë“œë°±ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "total_questions": session.question_count
        }
    
    # Generate next question
    try:
        next_question = await nvidia_service.generate_interview_question(
            profile=session.profile,
            jd_text=session.jd_text,
            conversation_history=session.conversation_history,
            persona=session.persona
        )
        
        session.conversation_history.append({
            "role": "interviewer",
            "content": next_question,
            "timestamp": datetime.now().isoformat()
        })
        session.question_count += 1
        
        return {
            "session_id": session_id,
            "question": next_question,
            "question_number": session.question_count,
            "total_questions": session.max_questions,
            "status": "in_progress"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to generate question: {str(e)}")


@router.get("/{session_id}/feedback", response_model=InterviewFeedbackResponse)
async def get_interview_feedback(session_id: str):
    """
    Get feedback summary for a completed interview session.
    """
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session = active_sessions[session_id]
    
    if not session.ended_at:
        session.ended_at = datetime.now().isoformat()
    
    # Calculate duration
    start = datetime.fromisoformat(session.started_at)
    end = datetime.fromisoformat(session.ended_at)
    duration = int((end - start).total_seconds())
    
    # Generate feedback (in production, use AI for detailed analysis)
    feedback_summary = f"""
ë©´ì ‘ ì„¸ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ“Š ìš”ì•½:
- ì´ {session.question_count}ê°œì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì…¨ìŠµë‹ˆë‹¤.
- ì†Œìš” ì‹œê°„: {duration // 60}ë¶„ {duration % 60}ì´ˆ
- ë©´ì ‘ê´€ ìŠ¤íƒ€ì¼: {session.persona}

ğŸ’¡ í”¼ë“œë°±:
ì „ë°˜ì ìœ¼ë¡œ ë©´ì ‘ì— ì„±ì‹¤íˆ ì„í•´ì£¼ì…¨ìŠµë‹ˆë‹¤. 
ê¸°ìˆ ì  ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì˜ êµ¬ì²´ì„±ì„ ë†’ì´ì‹œë©´ ë” ì¢‹ì€ ì¸ìƒì„ ë‚¨ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """.strip()
    
    return InterviewFeedbackResponse(
        session_id=session_id,
        total_questions=session.question_count,
        duration_seconds=duration,
        conversation=session.conversation_history,
        feedback_summary=feedback_summary,
        scores={
            "technical_accuracy": 75,
            "communication": 80,
            "problem_solving": 70,
            "overall": 75
        }
    )


# ============ WebSocket Endpoint ============

@router.websocket("/ws/{session_id}")
async def interview_websocket(websocket: WebSocket, session_id: str):
    """
    Real-time interview WebSocket connection.
    
    Message format (client -> server):
    {
        "type": "answer",
        "content": "ì‚¬ìš©ì ë‹µë³€ í…ìŠ¤íŠ¸"
    }
    
    Message format (server -> client):
    {
        "type": "question" | "audio" | "status" | "error",
        "content": "ì§ˆë¬¸/ìƒíƒœ í…ìŠ¤íŠ¸",
        "audio_base64": "base64 encoded audio (for audio type)"
    }
    """
    await websocket.accept()
    
    if session_id not in active_sessions:
        await websocket.send_json({
            "type": "error",
            "content": "Session not found. Please start a new interview."
        })
        await websocket.close()
        return
    
    session = active_sessions[session_id]
    
    try:
        # Send initial status
        await websocket.send_json({
            "type": "status",
            "content": "ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤."
        })
        
        # Send first question with audio
        if session.conversation_history:
            last_question = session.conversation_history[-1]["content"]
            
            # Send text first
            await websocket.send_json({
                "type": "question",
                "content": last_question,
                "question_number": session.question_count
            })
            
            # Stream audio
            try:
                async for audio_chunk in elevenlabs_service.text_to_speech_stream(
                    last_question,
                    persona=session.persona
                ):
                    await websocket.send_json({
                        "type": "audio",
                        "audio_base64": base64.b64encode(audio_chunk).decode()
                    })
            except Exception as e:
                print(f"Audio streaming error: {e}")
        
        # Listen for answers
        while True:
            data = await websocket.receive_json()
            
            if data.get("type") == "answer":
                answer = data.get("content", "")
                
                # Record answer
                session.conversation_history.append({
                    "role": "candidate",
                    "content": answer,
                    "timestamp": datetime.now().isoformat()
                })
                
                # Check if interview should end
                if session.question_count >= session.max_questions:
                    session.ended_at = datetime.now().isoformat()
                    await websocket.send_json({
                        "type": "status",
                        "content": "ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!"
                    })
                    break
                
                # Generate next question
                await websocket.send_json({
                    "type": "status",
                    "content": "ë‹µë³€ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
                })
                
                next_question = await nvidia_service.generate_interview_question(
                    profile=session.profile,
                    jd_text=session.jd_text,
                    conversation_history=session.conversation_history,
                    persona=session.persona
                )
                
                session.conversation_history.append({
                    "role": "interviewer",
                    "content": next_question,
                    "timestamp": datetime.now().isoformat()
                })
                session.question_count += 1
                
                # Send question
                await websocket.send_json({
                    "type": "question",
                    "content": next_question,
                    "question_number": session.question_count
                })
                
                # Stream audio
                try:
                    async for audio_chunk in elevenlabs_service.text_to_speech_stream(
                        next_question,
                        persona=session.persona
                    ):
                        await websocket.send_json({
                            "type": "audio",
                            "audio_base64": base64.b64encode(audio_chunk).decode()
                        })
                except Exception as e:
                    print(f"Audio streaming error: {e}")
            
            elif data.get("type") == "end":
                session.ended_at = datetime.now().isoformat()
                await websocket.send_json({
                    "type": "status",
                    "content": "ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                })
                break
    
    except WebSocketDisconnect:
        print(f"WebSocket disconnected for session {session_id}")
    except Exception as e:
        await websocket.send_json({
            "type": "error",
            "content": f"Error: {str(e)}"
        })
    finally:
        await websocket.close()
